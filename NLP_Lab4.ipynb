{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sys import argv\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "Nx-SiwQbOo61"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDaBDZxrOpVu",
        "outputId": "39fda793-9843-46b6-8328-c0ab08610750"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78722856d7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(\n",
        "            model, tok, text,\n",
        "            do_sample=True, max_length=100, repetition_penalty=5.0,\n",
        "            top_k=5, top_p=0.95, temperature=1,\n",
        "            num_beams=None,\n",
        "            no_repeat_ngram_size=3\n",
        "            ):\n",
        "          input_ids = tok.encode(text, return_tensors=\"pt\")\n",
        "          out = model.generate(\n",
        "              input_ids,\n",
        "              max_length=max_length,\n",
        "              repetition_penalty=repetition_penalty,\n",
        "              do_sample=do_sample,\n",
        "              top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "              num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "              pad_token_id=tok.eos_token_id\n",
        "              )\n",
        "          return list(map(tok.decode, out))\n"
      ],
      "metadata": {
        "id": "1rfJ1-whOqxN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tokenizer_and_model(model_name_or_path):\n",
        "    return GPT2Tokenizer.from_pretrained(model_name_or_path), GPT2LMHeadModel.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "id": "yx_xEqGBOsXu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
        "tok, model = load_tokenizer_and_model(model_name)"
      ],
      "metadata": {
        "id": "tbm2FoseOtwd"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\"Тише!\" - прошептал рыбак. \"Любой шум заставит его убежать\".\n",
        "Я начал медленно разворачиваться, чувствуя, как холодеет от напряжения. Пытаясь осторожнее удить рыбу, чтобы не\"\"\""
      ],
      "metadata": {
        "id": "XFi-IJi-OvUl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated = generate(\n",
        "    model, tok, prompt,\n",
        "    do_sample=False,\n",
        "    max_length=120,\n",
        "    repetition_penalty=6.0,\n",
        "    top_k=3,\n",
        "    top_p=0.9,\n",
        "    temperature=0.2,\n",
        "    num_beams=15,\n",
        "    no_repeat_ngram_size=4\n",
        ")\n",
        "\n",
        "print(generated[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUmIX99eOw_d",
        "outputId": "bb4380d9-42a5-49eb-8791-e8a6436c17bb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Тише!\" - прошептал рыбак. \"Любой шум заставит его убежать\". \n",
            "Я начал медленно разворачиваться, чувствуя, как холодеет от напряжения. Пытаясь осторожнее удить рыбу, чтобы не спугнуть ее, я все время оглядывался по сторонам и прислушивался к звукам за спиной. Мне казалось, что кто-то подкрадывается ко мне со стороны реки. Я был уверен в том, что это тот самый человек, который преследовал меня с того самого момента, когда я вышел на берег. Но почему он так медлит? \n",
            "\n",
            "В этот момент\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5XqCjbmMPONV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}